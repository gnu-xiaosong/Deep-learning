{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costfcn_v(y, X, b, w):\n",
    "  \"\"\"Calculate the mean-squared error cost function for a bivariate linear regression.\n",
    "\n",
    "  Args:\n",
    "    y: 1D ndarray of the target variable.\n",
    "    X: 1D ndarray of the input features.\n",
    "    b: bias.\n",
    "    w: weight.\n",
    "\n",
    "  Returns:\n",
    "    Cost function value.\n",
    "  \"\"\"\n",
    "\n",
    "  y_hat = b + w * X\n",
    "  J = np.mean((y_hat - y) ** 2) / 2\n",
    "\n",
    "  return J\n",
    "\n",
    "def gradient_v(y, X, b, w):\n",
    "  \"\"\"Calculate gradients of the cost function.\n",
    "\n",
    "  Args:\n",
    "    y: 1D ndarray of the target variable.\n",
    "    X: 1D ndarray of the input features.\n",
    "    b: bias.\n",
    "    w: weight.\n",
    "\n",
    "  Returns:\n",
    "    dJ/db, dJ/dw.\n",
    "  \"\"\"\n",
    "\n",
    "  y_hat = b + w * X\n",
    "  dJdb = np.mean(y_hat - y)\n",
    "  dJdw = np.mean((y_hat - y) * X)\n",
    "\n",
    "  return dJdb, dJdw\n",
    "\n",
    "def graident_descent_v(y, X, alpha=0.1, tol=1.e-7):\n",
    "  \"\"\"Estimate parameters using a gradient decent algorithm.\n",
    "\n",
    "  Args:\n",
    "    y: 1D ndarray of the target variable.\n",
    "    X: 1D ndarray of the input features.\n",
    "    alpha: learning rate.\n",
    "    tol: Tolerance. If the relative change of the cost function is less than tol,\n",
    "      the cost function is considered to have converged to a minimum.\n",
    "\n",
    "  Returns:\n",
    "    Parameter estimates, b and w.\n",
    "  \"\"\"\n",
    "\n",
    "  max_iter = 10000  # maximum iteration\n",
    "  b = np.random.uniform()  # Random initial value of b.\n",
    "  w = np.random.uniform()  # Random initial value of w.\n",
    "\n",
    "  J0 = costfcn_v(y, X, b, w)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    # Update parameters.\n",
    "    dJdb, dJdw = gradient_v(y, X, b, w)\n",
    "    b -= alpha * dJdb\n",
    "    w -= alpha * dJdw\n",
    "\n",
    "    J = costfcn_v(y, X, b, w)\n",
    "    print(f'{i}: b = {b}, w = {w}, J = {J}')\n",
    "\n",
    "    # Check convergence.\n",
    "    if np.abs((J-J0) / J0) < tol:\n",
    "      break\n",
    "    else:\n",
    "      J0 = J\n",
    "\n",
    "  if i == max_iter:\n",
    "    print('Maximum iteration reached before convergence.')\n",
    "\n",
    "  return b, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the cost function\n",
    "def cost_function(X, y, b, w):\n",
    "    m = len(y)\n",
    "    predictions = X.dot(w) + b\n",
    "    cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the gradient descent function\n",
    "def gradient_descent(X, y, b, w, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = np.zeros(iterations)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        predictions = X.dot(w) + b\n",
    "        b_gradient = -(1 / m) * np.sum(y - predictions)\n",
    "        w_gradient = -(1 / m) * X.T.dot(y - predictions)\n",
    "\n",
    "        b = b - learning_rate * b_gradient\n",
    "        w = w - learning_rate * w_gradient\n",
    "\n",
    "        cost_history[i] = cost_function(X, y, b, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting hyperparameters\n",
    "learning_rate = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running gradient descent\n",
    "estimated_b, estimated_w, cost_history = gradient_descent(X, y, initial_b, initial_w, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
