{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costfcn_v(y, X, b, w):\n",
    "  \"\"\"Calculate the mean-squared error cost function for a bivariate linear regression.\n",
    "\n",
    "  Args:\n",
    "    y: 1D ndarray of the target variable.\n",
    "    X: 1D ndarray of the input features.\n",
    "    b: bias.\n",
    "    w: weight.\n",
    "\n",
    "  Returns:\n",
    "    Cost function value.\n",
    "  \"\"\"\n",
    "\n",
    "  y_hat = b + w * X\n",
    "  J = np.mean((y_hat - y) ** 2) / 2\n",
    "\n",
    "  return J\n",
    "\n",
    "def gradient_v(y, X, b, w):\n",
    "  \"\"\"Calculate gradients of the cost function.\n",
    "\n",
    "  Args:\n",
    "    y: 1D ndarray of the target variable.\n",
    "    X: 1D ndarray of the input features.\n",
    "    b: bias.\n",
    "    w: weight.\n",
    "\n",
    "  Returns:\n",
    "    dJ/db, dJ/dw.\n",
    "  \"\"\"\n",
    "\n",
    "  y_hat = b + w * X\n",
    "  dJdb = np.mean(y_hat - y)\n",
    "  dJdw = np.mean((y_hat - y) * X)\n",
    "\n",
    "  return dJdb, dJdw\n",
    "\n",
    "def graident_descent_v(y, X, alpha=0.1, tol=1.e-7):\n",
    "  \"\"\"Estimate parameters using a gradient decent algorithm.\n",
    "\n",
    "  Args:\n",
    "    y: 1D ndarray of the target variable.\n",
    "    X: 1D ndarray of the input features.\n",
    "    alpha: learning rate.\n",
    "    tol: Tolerance. If the relative change of the cost function is less than tol,\n",
    "      the cost function is considered to have converged to a minimum.\n",
    "\n",
    "  Returns:\n",
    "    Parameter estimates, b and w.\n",
    "  \"\"\"\n",
    "\n",
    "  max_iter = 10000  # maximum iteration\n",
    "  b = np.random.uniform()  # Random initial value of b.\n",
    "  w = np.random.uniform()  # Random initial value of w.\n",
    "\n",
    "  J0 = costfcn_v(y, X, b, w)\n",
    "\n",
    "  for i in range(max_iter):\n",
    "    # Update parameters.\n",
    "    dJdb, dJdw = gradient_v(y, X, b, w)\n",
    "    b -= alpha * dJdb\n",
    "    w -= alpha * dJdw\n",
    "\n",
    "    J = costfcn_v(y, X, b, w)\n",
    "    print(f'{i}: b = {b}, w = {w}, J = {J}')\n",
    "\n",
    "    # Check convergence.\n",
    "    if np.abs((J-J0) / J0) < tol:\n",
    "      break\n",
    "    else:\n",
    "      J0 = J\n",
    "\n",
    "  if i == max_iter:\n",
    "    print('Maximum iteration reached before convergence.')\n",
    "\n",
    "  return b, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions = X.dot(theta)\n",
    "    cost = (1/(2*m)) * np.sum(np.square(predictions - y))\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = np.zeros(iterations)\n",
    "    for i in range(iterations):\n",
    "        predictions = X.dot(theta)\n",
    "        errors = predictions - y\n",
    "        gradient = (1/m) * X.T.dot(errors)\n",
    "        theta -= learning_rate * gradient\n",
    "        cost_history[i] = compute_cost(X, y, theta)\n",
    "    return theta, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "m = 1000\n",
    "b = 0.5\n",
    "w = [3, 1, -0.5, 10]\n",
    "X = np.random.uniform(-10, 10, (m, 4))\n",
    "y = b + X @ w + np. random.normal(0, 2, m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to X for the bias term\n",
    "X_b = np.c_[np.ones((m,1)),X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "theta = np. zeros(5) # Including bias term\n",
    "learning_rate = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gradient descent\n",
    "theta_final, cost_history = gradient_descent(X_b, y, theta, learning_rate, iterations)\n",
    "\n",
    "print(\"Parameter estimates:\")\n",
    "print(\"Intercept:\", theta_final[0])\n",
    "print(\"Coefficients:\", theta_final[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLot cost history to visualize convergence\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, iterations +1), cost_history, color='blue')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Gradient Descent Convergence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the functions\n",
    "def costfcn_v(y, X, b, w):\n",
    "    \"\"\"Calculate the mean-squared error cost function for a bivariate linear regression.\n",
    "\n",
    "    Args:\n",
    "        y: 1D ndarray of the target variable.\n",
    "        X: 1D ndarray of the input features.\n",
    "        b: bias.\n",
    "        w: weight.\n",
    "\n",
    "    Returns:\n",
    "        Cost function value.\n",
    "    \"\"\"\n",
    "    y_hat = b + w * X\n",
    "    J = np.mean((y_hat - y) ** 2) / 2\n",
    "    return J\n",
    "\n",
    "def gradient_v(y, X, b, w):\n",
    "    \"\"\"Calculate gradients of the cost function.\n",
    "\n",
    "    Args:\n",
    "        y: 1D ndarray of the target variable.\n",
    "        X: 1D ndarray of the input features.\n",
    "        b: bias.\n",
    "        w: weight.\n",
    "\n",
    "    Returns:\n",
    "        dJ/db, dJ/dw.\n",
    "    \"\"\"\n",
    "    y_hat = b + w * X\n",
    "    dJdb = np.mean(y_hat - y)\n",
    "    dJdw = np.mean((y_hat - y) * X)\n",
    "    return dJdb, dJdw\n",
    "\n",
    "def gradient_descent_v(y, X, alpha=0.1, tol=1.e-7):\n",
    "    \"\"\"Estimate parameters using a gradient descent algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: 1D ndarray of the target variable.\n",
    "        X: 1D ndarray of the input features.\n",
    "        alpha: learning rate.\n",
    "        tol: Tolerance. If the relative change of the cost function is less than tol,\n",
    "        the cost function is considered to have converged to a minimum.\n",
    "\n",
    "    Returns:\n",
    "        Parameter estimates, b and w.\n",
    "    \"\"\"\n",
    "    max_iter = 10000  # maximum iteration\n",
    "    b = np.random.uniform()  # Random initial value of b.\n",
    "    w = np.random.uniform()  # Random initial value of w.\n",
    "    J0 = costfcn_v(y, X, b, w)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # Update parameters.\n",
    "        dJdb, dJdw = gradient_v(y, X, b, w)\n",
    "        b -= alpha * dJdb\n",
    "        w -= alpha * dJdw\n",
    "        J = costfcn_v(y, X, b, w)\n",
    "        print(f'{i}: b = {b}, w = {w}, J = {J}')\n",
    "\n",
    "        # Check convergence.\n",
    "        if np.abs((J-J0) / J0) < tol:\n",
    "            break\n",
    "        else:\n",
    "            J0 = J\n",
    "\n",
    "    if i == max_iter:\n",
    "        print('Maximum iteration reached before convergence.')\n",
    "\n",
    "    return b, w\n",
    "\n",
    "# Sample data generation\n",
    "m = 1000\n",
    "b_true = 0.5\n",
    "w_true = 3\n",
    "X = np.random.uniform(-10, 10, m)\n",
    "y = b_true + w_true * X + np.random.normal(0, 2, m)\n",
    "\n",
    "# Run gradient descent\n",
    "b_estimate, w_estimate = gradient_descent_v(y, X)\n",
    "\n",
    "# Print the estimated parameter values\n",
    "print(\"\\nEstimated parameter values:\")\n",
    "print(\"Intercept (b_estimate):\", b_estimate)\n",
    "print(\"Weight (w_estimate):\", w_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
